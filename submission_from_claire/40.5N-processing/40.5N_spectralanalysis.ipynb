{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last edited by Claire Valva on September 4, 2018\n",
    "# Spectral analysis is performed on 40.5N data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set whether or not to reload data \n",
    "#or use data saved from an old session\n",
    "do_trends = False  \n",
    "run_fresh = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from scipy.signal import get_window, csd\n",
    "from scipy.fftpack import fft, ifft, fftfreq, fftshift, ifftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.cm as cm\n",
    "from math import pi\n",
    "import matplotlib.ticker as tck\n",
    "import datetime\n",
    "from sympy import solve, Poly, Eq, Function, exp, re, im\n",
    "from PyEMD import EMD\n",
    "from netCDF4 import Dataset, num2date # This is to read .nc files and time array\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clairev/python-climate-data-processing/submission_from_claire/functions_forspectralanalysis.py:75: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  zonal_spacing = 1/zonal_spacing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook functions_forspectralanalysis.ipynb to script\n",
      "[NbConvertApp] Writing 4656 bytes to functions_forspectralanalysis.py\n"
     ]
    }
   ],
   "source": [
    "#import own functions from functions_forspectralanalysis.py\n",
    "#functions are based off of those in spectral_analysis_tests.ipynb \n",
    "#but edited so that they can be used in multiple notebooks\n",
    "from functions_forspectralanalysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and edit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
       "    dimensions(sizes): longitude(240), time(55520)\n",
       "    variables(dimensions): float32 \u001b[4mz\u001b[0m(time,longitude)\n",
       "    groups: "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import file\n",
    "filepath = '/home/clairev/uncategorized-data/1979-2016-300hPa-40.5N-z.nc' # Location of the file\n",
    "fileobj = Dataset(filepath, mode='r')\n",
    "\n",
    "# Check what's in there\n",
    "fileobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set indicies/number of things\n",
    "number_entries = int(fileobj.dimensions['time'].size)\n",
    "number_days = int(number_entries / 4)\n",
    "number_lon = fileobj.dimensions['longitude'].size\n",
    "year_number = 2016 - 1979 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load coordinates\n",
    "#so height[i] is the geopotential height at a given time\n",
    "height = fileobj.variables['z'][:]\n",
    "g_inv = 1/9.81\n",
    "height = height*g_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create time array\n",
    "time_list = []\n",
    "for i in range(0,55520):\n",
    "    time_list.append(i*6)\n",
    "tunit = \"hours since 1979-01-01T00:00:00Z\"\n",
    "tarray = num2date(time_list,units = tunit,calendar = 'gregorian')\n",
    "\n",
    "#create longitude array\n",
    "lon_increment = 1.5 # The increment of each longitude grid is 1.5\n",
    "lon_list = [i * lon_increment for i in range(240)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_fresh:\n",
    "\n",
    "#get lists and then merge together as a dataframe\n",
    "    lon_list = [lon_list[k]\n",
    "               for i in range(number_entries)\n",
    "               for k in range(number_lon)]\n",
    "\n",
    "    z_temp = [height[i][k]\n",
    "              for i in range(number_entries)\n",
    "              for k in range(number_lon)]\n",
    "\n",
    "    date_list = [tarray[i]\n",
    "               for i in range(number_entries)\n",
    "               for k in range(number_lon)]\n",
    "    \n",
    "    #make this a dataframe\n",
    "    d = {'datetime' : date_list, 'lon': lon_list,\n",
    "                    'z' : z_temp}\n",
    "    geopot_df = pd.DataFrame(d)\n",
    "    \n",
    "    #get day/month/year separately for groupby\n",
    "    geopot_df['month'] = geopot_df['datetime'].apply(lambda x: x.month)\n",
    "    geopot_df['day'] = geopot_df['datetime'].apply(lambda x: x.day)\n",
    "    geopot_df['year'] = geopot_df['datetime'].apply(lambda x: x.year)\n",
    "    \n",
    "    #sort into seasons    \n",
    "    geopot_df[\"season\"] = geopot_df[\"month\"].apply(lambda x: season_sort(x))\n",
    "    \n",
    "    \n",
    "    # Create storage object with filename `processed_data`\n",
    "    data_store = pd.HDFStore('processed_data.h5')\n",
    "\n",
    "    # Put DataFrame into the object setting the key as 'preprocessed_df'\n",
    "    data_store['preprocessed_geopot'] = geopot_df\n",
    "    data_store.close()\n",
    "    \n",
    "else:\n",
    "        # Access data store\n",
    "    data_store = pd.HDFStore('processed_data.h5')\n",
    "\n",
    "    # Retrieve data using key\n",
    "    geopot_df = data_store['preprocessed_geopot']\n",
    "    data_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform zonal fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get fft results at each date over entire longitude\n",
    "fft_zonal_result = [geopot_fft(height[k]) \n",
    "                    for k in range(number_entries)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform time fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detrending\n",
    "\n",
    "detrend all data using results from zonal fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of years and seasons to perform transform/detrend on\n",
    "years = range(1979,2017)\n",
    "seasons = [\"winter\", \"spring\", \"summer\", \"fall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define some functions which depend on the files imported earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendsfordf(year, season):\n",
    "    frame = geopot_df.query(query_string(year, season, 9))\n",
    "    \n",
    "    trend_list = [pairwavenum(k, frame, tarray, fft_zonal_result) \n",
    "                  for k in range(len(zonal_spacing))]\n",
    "    \n",
    "    return(trend_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO DO: this function gets a lot of runtime warnings, likely from the fsolve - would be nice to fix it up later on // for time being just come back and give an option to pickle it later\n",
    "\n",
    "##### TO DO: should be right, but check on the time indexing after finish  transforming back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_subtract(time, frame, tarray, fft_zonal_result, trend_list):\n",
    "    #since gettimes depends on frame, get frame first\n",
    "    \n",
    "    #get first and last timestamp\n",
    "    tmin, tmax = gettimes(frame, tarray)\n",
    " \n",
    "    #get the time steps at the beginning and end of the seasons\n",
    "    iter_list = time - tmin\n",
    "    \n",
    "    #get the results and then subtract the list\n",
    "    results = fft_zonal_result[time]\n",
    "    tosub = [sublist[1][iter_list - 1] for sublist in trend_list]\n",
    "    \n",
    "    results = results - tosub\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendsfordf(year, season):\n",
    "    frame = geopot_df.query(query_string(year, season, 9))\n",
    "    \n",
    "    #get trends\n",
    "    trend_list = [pairwavenum(k, frame, tarray, fft_zonal_result) \n",
    "                  for k in range(len(zonal_spacing))]\n",
    "    \n",
    "    tmin, tmax = gettimes(frame, tarray)\n",
    "    \n",
    "    #adjust the list\n",
    "    adjusted_list = [coeff_subtract(time, frame, tarray, fft_zonal_result, trend_list) for time in range(tmin, tmax+tmin)]\n",
    "    \n",
    "    #perform ifft on the list\n",
    "    adjusted_list_ifft = [ifft(sublist) for sublist in adjusted_list]\n",
    "    \n",
    "    return(season, year, trend_list, adjusted_list, adjusted_list_ifft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the trends in fourier coefficients\n",
    "if do_trends == True:\n",
    "    trends_all_list = [trendsfordf(time, season) for season in seasons\n",
    "                       for time in years]\n",
    "    \n",
    "    import pickle\n",
    "\n",
    "    file_Name = \"test_trends_pickle\"\n",
    "    file_pickle = open(file_Name,'wb') \n",
    "\n",
    "    pickle.dump(trends_all_list,file_pickle)\n",
    "    file_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_trends == False:\n",
    "    import pickle\n",
    "    \n",
    "    file_Name = \"test_trends_pickle\"\n",
    "    \n",
    "    file_pickle = open(file_Name, \"rb\")\n",
    "    \n",
    "    trends_all_list = pickle.load(file_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that the structre of trends_all_list is:\n",
    "\n",
    "trends = [time, season, trends, adjusted forier coeffs, ifft of adjusted forier coeffs] * 152\n",
    "\n",
    "where time is a year\n",
    "season is a season\n",
    "trends for that time and season are 240 entries of changing trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull everything out of the list\n",
    "season_index = [sublist[0] for sublist in trends_all_list]\n",
    "year_index = [sublist[1] for sublist in trends_all_list]\n",
    "trend_index = [sublist[2] for sublist in trends_all_list]\n",
    "adjcof_index = [sublist[3] for sublist in trends_all_list]\n",
    "untrend_index = [sublist[4] for sublist in trends_all_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten list of detrended z values\n",
    "flatten_df_untrend = [item for sublist in untrend_index for item in sublist]\n",
    "flatten_df_untrend = [item for sublist in flatten_df_untrend for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of same length for df binding - season, year, lon lists\n",
    "season_df_list = []\n",
    "year_df_list = []\n",
    "lon_df_list = []\n",
    "\n",
    "for i in range(len(untrend_index)):\n",
    "    for j in range(len(untrend_index[i])):\n",
    "        for k in range(240):\n",
    "            entry = season_index[i]\n",
    "            yr = year_index[i]\n",
    "            lon = lon_list[k]\n",
    "            \n",
    "            season_df_list.append(entry)\n",
    "            year_df_list.append(yr)\n",
    "            lon_df_list.append(lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"season\": season_df_list, \"year\": year_df_list,\n",
    "     \"lon\": lon_df_list, \"adj_z\": flatten_df_untrend}\n",
    "\n",
    "untrend_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_fft(season, year, longitude):\n",
    "    #function that applies fft to geo height data by year, season, longitude\n",
    "    \n",
    "    frame = untrend_df.query(query_string_v2(year, season, longitude))\n",
    "    \n",
    "    #get spacing\n",
    "    num_entries = len(frame[\"adj_z\"])\n",
    "    spacing = fftfreq(num_entries, 0.25)\n",
    "    \n",
    "    #apply fft\n",
    "    fft_coeff = fft(frame[\"adj_z\"])\n",
    "    ck_coeff = fft_coeff/ num_entries\n",
    "    \n",
    "    #return info and the fft\n",
    "    return season, year, longitude, spacing, fft_coeff, ck_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get spectra of each individual season\n",
    "fft_total_list = [time_fft(sea, yr, lon) for sea in seasons \n",
    "                 for time in years \n",
    "                 for lon in lon_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
